{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ayushnangia/CAM-Back-Again.git\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "project_path = \"/path/repo/CAM_Back_Again\"\n",
    "sys.path.append(project_path)\n",
    "from convnext_func import Net2Head\n",
    "from replknet_func import *\n",
    "from utils import *\n",
    "from dataset_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(model, pretrained_path, num_classes):\n",
    "    pretrained_dict = torch.load(pretrained_path, map_location='cpu')\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and 'head' not in k}\n",
    "\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "    in_features = model.head.in_features\n",
    "    model.head = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High activation heat map generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "model_path = \"/modelpath\"\n",
    "train_dir = \"/input/path\"\n",
    "heatmap_output_dir = '/output/path'\n",
    "\n",
    "os.makedirs(heatmap_output_dir, exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    \"class_n\": 2,\n",
    "    \"unit_n\": 1024,\n",
    "    \"input_size\": 384,\n",
    "    \"size\": 12,\n",
    "    \"lr\": 1e-05,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"channels\": [128, 256, 512, 1024]\n",
    "}\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((model_config[\"input_size\"], model_config[\"input_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def load_model(model_path):\n",
    "    if 'convnext' in model_path.lower():\n",
    "        model = timm.create_model(\"convnext_base_384_in22ft1k\", pretrained=False, num_classes=model_config[\"class_n\"])\n",
    "    elif 'replknet' in model_path.lower():\n",
    "        model_config[\"model_name\"] = \"RepLKNet-31B\"\n",
    "        model_config[\"channels\"] = [128,256,512,1024]\n",
    "        model = build_model(model_config)  # Make sure you have this function defined or imported\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_path}\")\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "def get_feature_maps(x, model):\n",
    "    features = []\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(output)\n",
    "\n",
    "    for name, module in reversed(list(model.named_modules())):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            handle = module.register_forward_hook(hook_fn)\n",
    "            break\n",
    "\n",
    "    _ = model(x)\n",
    "    handle.remove()\n",
    "\n",
    "    return features[0]\n",
    "\n",
    "def get_cam_heatmap(features, model, target_class):\n",
    "    b, c, h, w = features.shape\n",
    "    features = features.reshape(c, h*w)\n",
    "\n",
    "    if hasattr(model, 'head'):\n",
    "        weights = model.head.weight.data[target_class]\n",
    "    elif hasattr(model, 'fc'):\n",
    "        weights = model.fc.weight.data[target_class]\n",
    "    else:\n",
    "        raise AttributeError(\"Model doesn't have 'head' or 'fc' attribute. Please check the model architecture.\")\n",
    "\n",
    "    heatmap = torch.mm(weights.unsqueeze(0), features).reshape(h, w)\n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap = heatmap.detach().cpu().numpy()\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
    "    return heatmap\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (model_config[\"input_size\"], model_config[\"input_size\"]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "    img = img / 255.0\n",
    "    img = (img - 0.5) / 0.5\n",
    "    return torch.FloatTensor(img).unsqueeze(0)\n",
    "\n",
    "def generate_heatmap(model, image_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    original_img = cv2.imread(image_path)\n",
    "    if original_img is None:\n",
    "        print(f\"Error reading image: {image_path}\")\n",
    "        return None, None\n",
    "\n",
    "    img = cv2.resize(original_img, (model_config[\"input_size\"], model_config[\"input_size\"]))\n",
    "\n",
    "    x = preprocess_image(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logit = model(x)\n",
    "\n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    target_class = idx[0].item()\n",
    "\n",
    "    features = get_feature_maps(x, model)\n",
    "    heatmap = get_cam_heatmap(features, model, target_class)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (model_config[\"input_size\"], model_config[\"input_size\"]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_colored, 0.4, 0)\n",
    "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return original_img, superimposed_img\n",
    "\n",
    "def process_directory(model, input_dir, output_dir):\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.*'))\n",
    "\n",
    "    for i, img_path in enumerate(image_files):\n",
    "        img_name = os.path.basename(img_path)\n",
    "        print(f\"Processing {img_name}\")\n",
    "\n",
    "        original, heatmap = generate_heatmap(model, img_path)\n",
    "        if original is None or heatmap is None:\n",
    "            continue\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title(\"Original\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.imshow(heatmap)\n",
    "        ax2.set_title(\"CAM\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{img_name}_heatmap.png\"))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = load_model(model_path)\n",
    "    process_directory(model, train_dir, heatmap_output_dir)\n",
    "    print(\"Heatmap generation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High activation based crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from skimage.measure import label, regionprops\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "model_path = \"/modelpath\"\n",
    "train_dir = \"/input/path\"\n",
    "crops_output_dir = '/output/path'\n",
    "\n",
    "os.makedirs(crops_output_dir, exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    \"class_n\": 2,\n",
    "    \"unit_n\": 1024,\n",
    "    \"input_size\": 384,\n",
    "    \"size\": 12,\n",
    "    \"lr\": 1e-04,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"channels\": [128, 256, 512, 1024]\n",
    "}\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((model_config[\"input_size\"], model_config[\"input_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def load_model(model_path):\n",
    "    if 'convnext' in model_path.lower():\n",
    "        model = timm.create_model(\"convnext_base_384_in22ft1k\", pretrained=False, num_classes=model_config[\"class_n\"])\n",
    "    elif 'replknet' in model_path.lower():\n",
    "        model_config[\"model_name\"] = \"RepLKNet-31B\"\n",
    "        model_config[\"channels\"] = [128,256,512,1024]\n",
    "        model = build_model(model_config)  # Make sure you have this function defined or imported\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_path}\")\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "def get_feature_maps(x, model):\n",
    "    features = []\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(output)\n",
    "\n",
    "    for name, module in reversed(list(model.named_modules())):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            handle = module.register_forward_hook(hook_fn)\n",
    "            break\n",
    "\n",
    "    _ = model(x)\n",
    "    handle.remove()\n",
    "\n",
    "    return features[0]\n",
    "\n",
    "def get_cam_heatmap(features, model, target_class):\n",
    "    b, c, h, w = features.shape\n",
    "    features = features.reshape(c, h*w)\n",
    "\n",
    "    if hasattr(model, 'head'):\n",
    "        weights = model.head.weight.data[target_class]\n",
    "    elif hasattr(model, 'fc'):\n",
    "        weights = model.fc.weight.data[target_class]\n",
    "    else:\n",
    "        raise AttributeError(\"Model doesn't have 'head' or 'fc' attribute. Please check the model architecture.\")\n",
    "\n",
    "    heatmap = torch.mm(weights.unsqueeze(0), features).reshape(h, w)\n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap = heatmap.detach().cpu().numpy()\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
    "    return heatmap\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (model_config[\"input_size\"], model_config[\"input_size\"]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "    img = img / 255.0\n",
    "    img = (img - 0.5) / 0.5\n",
    "    return torch.FloatTensor(img).unsqueeze(0)\n",
    "\n",
    "def generate_heatmap(model, image_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    original_img = cv2.imread(image_path)\n",
    "    if original_img is None:\n",
    "        print(f\"Error reading image: {image_path}\")\n",
    "        return None, None\n",
    "\n",
    "    img = cv2.resize(original_img, (model_config[\"input_size\"], model_config[\"input_size\"]))\n",
    "\n",
    "    x = preprocess_image(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logit = model(x)\n",
    "\n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    target_class = idx[0].item()\n",
    "\n",
    "    features = get_feature_maps(x, model)\n",
    "    heatmap = get_cam_heatmap(features, model, target_class)\n",
    "\n",
    "    return original_img, heatmap\n",
    "\n",
    "def create_focused_crops(image, heatmap, num_crops=8, min_crop_size=224):\n",
    "    h, w = heatmap.shape\n",
    "    crops = []\n",
    "\n",
    "    local_max = np.zeros_like(heatmap)\n",
    "    for i in range(1, h-1):\n",
    "        for j in range(1, w-1):\n",
    "            if heatmap[i, j] > max(heatmap[i-1:i+2, j-1:j+2].flatten()):\n",
    "                local_max[i, j] = heatmap[i, j]\n",
    "\n",
    "    coords = np.column_stack(np.where(local_max > 0))\n",
    "    intensities = local_max[local_max > 0]\n",
    "    sorted_indices = np.argsort(intensities)[::-1]\n",
    "\n",
    "    for idx in sorted_indices[:num_crops]:\n",
    "        y, x = coords[idx]\n",
    "\n",
    "        intensity = intensities[idx]\n",
    "        crop_size = int(min_crop_size + (min_crop_size * intensity))\n",
    "        crop_size = min(crop_size, min(image.shape[0], image.shape[1]))\n",
    "\n",
    "        y1 = max(0, y - crop_size // 2)\n",
    "        x1 = max(0, x - crop_size // 2)\n",
    "        y2 = min(image.shape[0], y1 + crop_size)\n",
    "        x2 = min(image.shape[1], x1 + crop_size)\n",
    "\n",
    "        if y2 - y1 < min_crop_size:\n",
    "            y1 = max(0, y2 - min_crop_size)\n",
    "        if x2 - x1 < min_crop_size:\n",
    "            x1 = max(0, x2 - min_crop_size)\n",
    "\n",
    "        crop = image[y1:y2, x1:x2]\n",
    "\n",
    "        if crop.shape[:2] != (min_crop_size, min_crop_size):\n",
    "            crop = cv2.resize(crop, (min_crop_size, min_crop_size))\n",
    "\n",
    "        crops.append(crop)\n",
    "\n",
    "    while len(crops) < num_crops:\n",
    "        y = random.randint(0, image.shape[0] - min_crop_size)\n",
    "        x = random.randint(0, image.shape[1] - min_crop_size)\n",
    "        crop = image[y:y+min_crop_size, x:x+min_crop_size]\n",
    "        crops.append(crop)\n",
    "\n",
    "    return crops\n",
    "\n",
    "def process_directory(model, input_dir, output_dir):\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.*'))\n",
    "\n",
    "    for i, img_path in enumerate(image_files):\n",
    "        img_name = os.path.basename(img_path)\n",
    "        print(f\"Processing {img_name}\")\n",
    "\n",
    "        original, heatmap = generate_heatmap(model, img_path)\n",
    "        if original is None or heatmap is None:\n",
    "            continue\n",
    "\n",
    "        crops = create_focused_crops(original, heatmap, num_crops=8, min_crop_size=224)\n",
    "\n",
    "        for j, crop in enumerate(crops):\n",
    "            crop_name = f\"{os.path.splitext(img_name)[0]}_crop_{j}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_dir, crop_name), crop)\n",
    "\n",
    "def main():\n",
    "    model = load_model(model_path)\n",
    "    process_directory(model, train_dir, crops_output_dir)\n",
    "    print(\"High activation crop generation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
